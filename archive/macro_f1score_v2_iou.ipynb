{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "numbers = rng.choice(20, size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  7,  1, 17, 11, 13,  4,  2, 16,  8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = 130203\n",
    "rank = 0\n",
    "world_size = 4\n",
    "\n",
    "indices = list(range(total_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_0 = indices[0:total_size:world_size]\n",
    "indices_1 = indices[1:total_size:world_size]\n",
    "indices_2 = indices[2:total_size:world_size]\n",
    "indices_3 = indices[3:total_size:world_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32551, 32551, 32551, 32550)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices_0), len(indices_1), len(indices_2), len(indices_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4차 3번 : 재활용\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "# 평가 : Macro F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our f1 score (class 별로 f1score x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_f1score():\n",
    "    with open('./dataset/trash/val/valcoco.json') as f:\n",
    "        data_dict = json.load(f)\n",
    "    realdata = data_dict['annotations']\n",
    "\n",
    "    real = {}\n",
    "    for data in realdata:\n",
    "        try:\n",
    "            if real[data['image_id']]:\n",
    "                if data['category_id'] in real[data['image_id']] :                \n",
    "                    continue\n",
    "                else :\n",
    "                    real[data['image_id']].append(data['category_id'])\n",
    "        except:\n",
    "            real[data['image_id']] = [data['category_id']]\n",
    "\n",
    "    # predict\n",
    "    with open('./result.bbox.json') as f:\n",
    "        pred = json.load(f)\n",
    "        \n",
    "    predict = {}\n",
    "    for data in pred:\n",
    "        try:\n",
    "            if predict[data['image_id']]: \n",
    "                if data['category_id'] in predict[data['image_id']] :                \n",
    "                    continue\n",
    "                else :\n",
    "                    predict[data['image_id']].append(data['category_id'])\n",
    "        except:\n",
    "            predict[data['image_id']] = [data['category_id']]\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for index in real.keys(): # image index\n",
    "        try:\n",
    "            p = set(predict[index])\n",
    "        except:\n",
    "            p = set()\n",
    "\n",
    "        r = set(real[index])\n",
    "        \n",
    "        TP += len(r&p)\n",
    "        FP += (len(p) - len(r&p))\n",
    "        FN += (len(r) - len(r&p))\n",
    "\n",
    "    precision = TP/(TP + FP)\n",
    "    recall = TP/(TP + FN)\n",
    "    f1score = 2*(precision * recall)/ (precision + recall)\n",
    "    print('f1 score = %.4f | TP = %d, FP = %d, FN = %d' %(f1score, TP, FP, FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI grand challenge f1 score(class별 f1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list(input_string):\n",
    "    # for i in input_string:\n",
    "    #     print(i)\n",
    "    tmp = \"\"\n",
    "    for i in input_string:\n",
    "        tmp += i\n",
    "    string_dict_list = tmp.strip(\"[]\")\n",
    "    # print(string_dict_list)\n",
    "\n",
    "    data = [x.strip(\"}\") for x in string_dict_list.split(',')]\n",
    "    data = [x.split(\":\")[-1].strip() for x in data]\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation(total_label, input_dict):\n",
    "    sorted_list = []\n",
    "    for i in input_dict[\"annotations\"]:\n",
    "        one_hot = [0 for x in range(len(total_label))]\n",
    "        file_name = i[\"file_name\"]\n",
    "        labels = []\n",
    "        if len(i[\"object\"]) > 0:\n",
    "            for obj in i[\"object\"]:\n",
    "                if len(obj[\"box\"]) > 0:\n",
    "                    labels.append(obj[\"label\"].replace(\"_\", \"\"))\n",
    "\n",
    "        unq_labels = sorted(list(set(labels)))\n",
    "        if len(unq_labels) > 0:\n",
    "            for unq in unq_labels:\n",
    "                one_hot[total_label.index(unq)] = 1\n",
    "\n",
    "        sorted_list.append([file_name, one_hot])\n",
    "\n",
    "    sorted_list = sorted(sorted_list, key=lambda k:k[0])\n",
    "\n",
    "    return np.array([x[1] for x in sorted_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_code(onehot):\n",
    "    codes = []\n",
    "    for i in onehot:\n",
    "        code = \"\"\n",
    "        for j in i:\n",
    "            code += str(j)\n",
    "        codes.append(code)\n",
    "\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track3_evaluation(pred, gt):\n",
    "    # Json 형식\n",
    "    with open(pred) as f: # 예측 파일\n",
    "        pred_dict = json.load(f)\n",
    "    with open(gt) as f: # 정답 파일\n",
    "        gt_dict = json.load(f)\n",
    "\n",
    "    # convert coco to 2020AGC\n",
    "    gt_dict = val_convert(gt_dict)\n",
    "        \n",
    "    # Get gournd-truth label list\n",
    "    total_labels = []\n",
    "    for gt in gt_dict[\"annotations\"]:\n",
    "        for obj in gt[\"object\"]:\n",
    "            total_labels.append(obj[\"label\"].replace(\"_\", \"\"))\n",
    "    unq_label = sorted(list(set(total_labels)))\n",
    "\n",
    "    # one hot 인코딩된 배열\n",
    "    y_pred = get_annotation(unq_label, pred_dict)\n",
    "    y_true = get_annotation(unq_label, gt_dict)\n",
    "    \n",
    "    multi_conf = multilabel_confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    \"\"\"\n",
    "    # 이미지 단위 f1-score\n",
    "    pred_code = to_code(y_pred)\n",
    "    gt_code = to_code(y_true)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(\"score:{}\".format(f1))\n",
    "    \n",
    "    return multi_conf, y_pred, y_true\n",
    "\n",
    "    # f1 = f1_score(y_true, y_pred, average='micro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_convert(gt_dict):\n",
    "    gt_list = [{} for _ in range(452)]\n",
    "\n",
    "    for idx, img in enumerate(gt_dict['images']):\n",
    "        gt_list[idx]['id'] = img['id']\n",
    "        gt_list[idx]['file_name'] = img['file_name']\n",
    "        gt_list[idx]['object'] = []\n",
    "        for obj in gt_dict['annotations']:\n",
    "            if img['id'] == obj['image_id']:\n",
    "                obj_sample = {}\n",
    "                obj_sample['box'] = obj['segmentation'][0]\n",
    "                obj_sample['label'] = 'c'+str(obj['category_id'])\n",
    "                gt_list[idx]['object'].append(obj_sample)\n",
    "    result = {'annotations':gt_list}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get iou from coco (x,y,w,h)\n",
    "def get_iou(pred_list, real_list):\n",
    "    pts_p = [pred_list[0] - pred_list[2]/2, pred_list[1] - pred_list[3]/2, \n",
    "             pred_list[0] + pred_list[2]/2, pred_list[1] + pred_list[3]/2]\n",
    "    \n",
    "    pts_r = [real_list[0] - real_list[2]/2, real_list[1] - real_list[3]/2,\n",
    "             real_list[0] + real_list[2]/2, real_list[1] + real_list[3]/2]\n",
    "    \n",
    "    x_left = max(pts_p[0], pts_r[0])\n",
    "    y_top = max(pts_p[1], pts_r[1])\n",
    "    x_right = min(pts_p[2], pts_r[2])\n",
    "    y_bottom = min(pts_p[3], pts_r[3])\n",
    "    \n",
    "    intersection = (x_right - x_left) * (y_bottom - y_top)\n",
    "    \n",
    "    pred_area = (pts_p[2] - pts_p[0]) * (pts_p[3] - pts_p[1])\n",
    "    real_area = (pts_r[2] - pts_r[0]) * (pts_r[3] - pts_r[1])\n",
    "    \n",
    "    iou = intersection/(pred_area+real_area-intersection)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:0.763309663362174\n"
     ]
    }
   ],
   "source": [
    "multi_conf, y_pred, y_true = track3_evaluation('t3_res_0030.json', 'dataset/trash/val/valcoco.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11,  16,  11,   2,   9, -10, -80])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = y_true-y_pred\n",
    "b.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0]\n",
      "[ 0  0 -1  0  0  0  0]\n",
      "[ 0 -1  0  0  0  1  1]\n",
      "[1 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0]\n",
      "[0 0 0 0 1 0 0]\n",
      "[0 0 0 0 1 0 0]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[ 0  0  0  0 -1  0  0]\n",
      "[ 0  0  0  0 -1  0  0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[ 0  0 -1  0  0  0  0]\n",
      "[ 0  1  0  0  0  1 -1]\n",
      "[0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[ 0  1  0  0  0  1 -1]\n",
      "[ 0  1 -1  0  0  1  0]\n",
      "[ 0  1 -1  0  0  1  0]\n",
      "[0 1 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[0 0 1 0 0 0 0]\n",
      "[0 0 0 0 1 0 0]\n",
      "[0 0 0 0 1 0 0]\n",
      "[0 0 0 0 1 1 0]\n",
      "[ 0  0 -1  0  1  1  0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[0 1 0 0 0 0 0]\n",
      "[ 0  1  0  0  0  1 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[0 0 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 0]\n",
      "[ 1 -1  1  0  0  0  0]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[1 0 1 0 0 0 0]\n",
      "[0 0 0 1 0 0 0]\n",
      "[ 0  1  1  0  0 -1  0]\n",
      "[ 0  1  0  0 -1 -1  0]\n",
      "[-1  0  0  0  0  0  0]\n",
      "[0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[0 0 0 1 0 1 0]\n",
      "[0 0 1 0 0 0 0]\n",
      "[ 1  0  0  0 -1  0 -1]\n",
      "[0 1 0 0 0 0 0]\n",
      "[-1  0  0 -1  0  0  0]\n",
      "[0 0 1 0 0 0 1]\n",
      "[ 0  1  1  0  0 -1  0]\n",
      "[0 0 1 0 0 0 0]\n",
      "[1 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0]\n",
      "[0 1 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[1 0 0 1 0 0 0]\n",
      "[0 0 0 1 0 0 0]\n",
      "[ 0  0 -1  0  0  0  0]\n",
      "[ 0  0 -1  0  0  1  1]\n",
      "[ 0  0  0  0 -1  0 -1]\n",
      "[ 0  1  0  0 -1  0 -1]\n",
      "[ 1  0  0  0  0  1 -1]\n",
      "[1 0 0 0 0 0 0]\n",
      "[ 0  1  0  0 -1  1  0]\n",
      "[ 0  0  0  0 -1  0  0]\n",
      "[0 0 0 0 0 0 1]\n",
      "[0 0 0 0 1 0 0]\n",
      "[0 1 0 0 0 0 0]\n",
      "[ 0  0  1  0  0  1 -1]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[0 0 0 0 1 0 0]\n",
      "[0 1 0 0 0 0 0]\n",
      "[ 0 -1  0  1  0  1  0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[-1  0  0 -1  0  0  0]\n",
      "[0 0 0 0 1 0 0]\n",
      "[0 1 0 0 0 0 0]\n",
      "[ 0  1  1  0  0  0 -1]\n",
      "[0 0 0 0 1 0 0]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[0 1 0 0 0 0 0]\n",
      "[ 0  0  0 -1  0  0  0]\n",
      "[ 0  0  0 -1  0  0  0]\n",
      "[0 0 1 0 0 0 0]\n",
      "[ 0  0  1  1 -1  0  0]\n",
      "[1 0 0 0 0 0 0]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0 -1  0  1  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0 -1  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0 -1  0  0  0  0 -1]\n",
      "[ 0 -1  0  0  0  0 -1]\n",
      "[ 1 -1  0  0  0  0 -1]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  1 -1  0  0 -1  0]\n",
      "[ 0  1  0  0  0 -1 -1]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0 -1 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0 -1 -1]\n",
      "[-1  0  0 -1  0  0  0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[ 0  0  0 -1  0  0 -1]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[0 0 1 0 0 0 0]\n",
      "[ 0  0  0  0 -1  0  0]\n",
      "[ 0  0  1  0 -1 -1  0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0 -1  0  0  0  0]\n",
      "[ 0  0 -1  0  0  0  0]\n",
      "[ 0  0  0  0 -1  0 -1]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  1 -1 -1]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0 -1 -1]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0 -1  0  0  0]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0 -1 -1]\n",
      "[ 0  0  0  0  0 -1 -1]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0  0  0  0  0 -1 -1]\n",
      "[ 0  0  0  0  0 -1  0]\n",
      "[ 0 -1  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0 -1  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[ 0 -1  0  0  0  0 -1]\n",
      "[ 0 -1  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0  0  0  0  0  0 -1]\n",
      "[ 0 -1  0  0  0  0  0]\n",
      "[ 0  0 -1  0  0  0  0]\n",
      "[ 0  0  0  0  0 -1  0]\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in b:\n",
    "    if i.sum() != 0:\n",
    "        print(i)\n",
    "        a +=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,   0,   9,   0,   1,   0, -57])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0, -1,  0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f81b7c444f640bcd28e7b46d1066f4663d856bc8436cdde2a500bc0abc8ca73"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('recycle': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
